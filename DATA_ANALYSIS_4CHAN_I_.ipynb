{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_1OUgO7tWi5"
      },
      "source": [
        " \\ \\ \\ \\ \\ \\  **WARNING!** \\ \\ \\ \\ \\ \\\n",
        " THE FOLLOWING CODE CONTAINS TOXIC SPEECH AND HARMFUL CONTENTS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIxc0AWqm5TF"
      },
      "source": [
        "Welcome to the Un4CHANate Analysis notebook I ! The present ipynb file is designed to help you research 4chan datasets from 4plebs. If you have already followed our 'DATA_LOADER_4CHAN_v2.ipynb' for the dataset chunking and merging the data into your specific timeframe, you are now ready to analyze the posts! The analysis will be pursued through two distinct notebooks: \"DATA_ANALYSIS_4CHAN_I_\" and \"DATA_ANALYSIS_4CHAN_II_\".\n",
        "\n",
        "This notebook will be twofold: on one hand, it will help you read your data; secondly, it will guide you through specific topic-modelling techniques, performed through a \"BERTopic\" model.  \n",
        "\n",
        "To help you better visualize the potential results of these techniques example graphs are added on the GitHub repository. Next to this as previously mentioned in the 'DATA_LOADER_4CHAN_v2' a demo dataset is also added to the repository, called 'demo_politically_incorrect_7d_jan_6_2021.csv'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyoYLi__pL3d"
      },
      "source": [
        "Phase I: Cleaning\n",
        "\n",
        "**STEP I:**\n",
        "\n",
        "Replace with the correct file_path towards your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "collapsed": true,
        "id": "in8DSQ6HbJcL",
        "outputId": "1b7d8c1b-9162-40ec-cd39-505c3695086c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_path = r'' #Write the path to your folder here\n",
        "all_comments = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "    all_comments = pd.read_csv(file_path)\n",
        "except pd.errors.ParserError:\n",
        "    print(f\"Error parsing file: {file_path}. Skipping.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading {file_path}: {e}\")\n",
        "\n",
        "print(f\"Total number of rows: {len(all_comments)}\")\n",
        "print(all_comments.info)\n",
        "all_comments.describe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXsjIjI-oT1H"
      },
      "source": [
        "**STEP II:**\n",
        "\n",
        "In our 4Chan data, we noticed there was an unwanted column: \"Unnamed: 0\". We thus proceeded to delete it.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "collapsed": true,
        "id": "U5uYGjXBkZfe",
        "outputId": "f50f9616-4b02-4be0-cd62-835f6fcd14db"
      },
      "outputs": [],
      "source": [
        "if 'Unnamed: 0' in all_comments.columns:\n",
        "    all_comments = all_comments.drop(columns=['Unnamed: 0'])\n",
        "    print(\"Column 'Unnamed: 0' successfully deleted.\")\n",
        "else:\n",
        "    print(\"Column 'Unnamed: 0' not found in the DataFrame.\")\n",
        "\n",
        "all_comments.info #let's see if it worked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hwgiGq7pCxe"
      },
      "source": [
        "**STEP III:**\n",
        "\n",
        "Let's now take a look at our data.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM8dEwoHdB4U",
        "outputId": "deef973e-2c76-4de9-a3f5-c5f5c0668b64"
      },
      "outputs": [],
      "source": [
        "print(len(all_comments))\n",
        "print(all_comments.sample(40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7NVMANWop0t"
      },
      "source": [
        "**STEP IV:**\n",
        "\n",
        "The \"time\" column is in unix timestamps, in order of seconds. It is not a very useful format: let's convert it to actual datetimes.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NoosKiPankoq",
        "outputId": "9a2646cd-3e71-43e5-f4ad-43b3f86cb3d5"
      },
      "outputs": [],
      "source": [
        "all_comments['time'] = pd.to_datetime(all_comments['time'], unit='s')\n",
        "print(all_comments.head(10))\n",
        "print(all_comments.tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_c_ZorpR7V"
      },
      "source": [
        "Phase 2: Topic modelling\n",
        "\n",
        "**STEP I:**\n",
        "\n",
        "Make sure to pip install the following:\n",
        "- !pip install transformers\n",
        "- !pip install bertopic umap-learn hdbscan sentence-transformers\n",
        "- !pip install NLTK\n",
        "\n",
        "Run cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EiT9EhZdoz_i",
        "outputId": "56f004aa-a776-4233-ed06-69c2f8765473"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from bertopic import BERTopic\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zK3FHSXD_Jt"
      },
      "source": [
        "**STEP II:**\n",
        "\n",
        "The following code sets up a pipeline to analyze text and uncover hidden topics.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "collapsed": true,
        "id": "9lSeVB7_lb92",
        "outputId": "28e9fd68-1a33-454a-e5e4-5889306fffe0"
      },
      "outputs": [],
      "source": [
        "sentence_model = SentenceTransformer('all-mpnet-base-v2') #This converts text into a format that a machine can understand\n",
        "# Dimensionality Reduction\n",
        "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=10) #The text embeddings are very detailed, often with hundreds of dimensions.\n",
        "                                                                                                  #To simplify and speed up analysis, we use UMAP to reduce these to just 5\n",
        "                                                                                                  #dimensions while preserving the structure of the data. \"min_dist\"\n",
        "                                                                                                  #controls how tightly the data points are packed after reduction. \"metric\"\n",
        "                                                                                                  #specifies how similarity between data points is measured; \"n_neighbors\"\n",
        "                                                                                                  #determines how much context each data point gets from its neighbors.\n",
        "\n",
        "\n",
        "# Clustering\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=2, metric='euclidean', cluster_selection_method='eom') #Once the data is reduced, the next step is to group similar\n",
        "                                                                                                                #comments together into clusters, which can be interpreted as\n",
        "                                                                                                                #potential topics. HDBSCAN does this by looking for dense groups\n",
        "                                                                                                                #of points. \"min_cluster_size\" determines the minimum size of\n",
        "                                                                                                                #clusters. \"min_samples\" deermines their stability and \"metric\"\n",
        "                                                                                                                #determines the way distances are measured.\n",
        "\n",
        "# Tokenization\n",
        "vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(1, 2), min_df=5) # To be analyzed, words and phrases need to be divided in smaller parts.  \"CountVectorizer\" does this by\n",
        "                                                                                       #by removing common stopwords, extracting single words and two-word combinations (ngram_range) and ignoring\n",
        "                                                                                        #words that appear in fewr than 5 comments (min_df=5)\n",
        "\n",
        "# Weighting Scheme\n",
        "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True) #this highlights the words that are unique to specific topics\n",
        "# Representation Tuning\n",
        "representation_model = KeyBERTInspired() #this step picks the most representative words or phrases for each topic.\n",
        "\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=sentence_model,\n",
        "    ctfidf_model=ctfidf_model,\n",
        "    representation_model=representation_model,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    vectorizer_model=vectorizer_model\n",
        ")                                                           #all previous tools are being now combined into one BERTopic model\n",
        "docs = all_comments['comment'].dropna().astype(str).tolist()\n",
        "fit_topic_model = topic_model.fit(docs)\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "#info\n",
        "topic_info = topic_model.get_topic_info()\n",
        "topic_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia8U7heBt5To"
      },
      "source": [
        "**STEP III:**\n",
        "\n",
        "*Optional* \n",
        "If there are too many topics we can force reduce them. Let's reduce the number to a 100 topics. This is an example, but any number of choice can be used.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I9AZAxVv3Uof",
        "outputId": "5200e988-e96e-47cf-c3eb-784d7dc5826b"
      },
      "outputs": [],
      "source": [
        "topic_model.reduce_topics(docs, nr_topics=100) #The forced reduction of topics is a highly sensitive part of the analysis. It is always a good idea to change it many times, and try with different outputs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-vFZLYXrTaA"
      },
      "source": [
        "**STEP IV:**\n",
        "\n",
        "We shall now work on the extracted topics with a few cleaning techniques. This phase can change depending on the data being analysed, as well as on the number of groups of topics extracted. In any case, it is always a good idea to remove stopwords from the topics, by using NLTK. After that, data must be checked to see how many outliers are in our data: topic \"-1\" is an automatically-produced row that contains all outliers. In our case, since there were too many outliers, we decided to force them into the other existing groups of topics.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Afr4_F8k-mSv",
        "outputId": "38af9960-66d1-4350-b49b-452ed84ef90c"
      },
      "outputs": [],
      "source": [
        "import nltk                                     #NLTK is maybe the best tool for removing stopwords. Unfortunately, many stopwords were used by our model to form the groups of topics,\n",
        "nltk.download('stopwords')                      #resulting in topics such as \"in\", \"of\" and so on. This step ensures no more stopwords are used in the analysis.\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "docs = docs\n",
        "docs_cleaned = []\n",
        "for doc in docs:\n",
        "  words = doc.split()\n",
        "  filtered_words = [w for w in words if not w.lower() in stop_words]\n",
        "  docs_cleaned.append(\" \".join(filtered_words))\n",
        "\n",
        "topics, probs = topic_model.fit_transform(docs_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP V:**\n",
        "\n",
        "Run cell below to see results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dkd6P5CT_IHx",
        "outputId": "41e4cf15-0e17-41a6-afde-e08d76446bc6"
      },
      "outputs": [],
      "source": [
        "topic_info = topic_model.get_topic_info()\n",
        "topic_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yn8CI7NrCOR"
      },
      "source": [
        "**STEP VI:**\n",
        "\n",
        "*Optional* We still had too many outliers. Let's use them by using a distribution method.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "csQb0qy9vU7n",
        "outputId": "6dbbb64f-d8e1-44d9-b55c-fa29597dd97a"
      },
      "outputs": [],
      "source": [
        "new_topics = topic_model.reduce_outliers(docs_cleaned, topics, strategy=\"distributions\") if topic_model._outliers else topics\n",
        "topic_model.update_topics(docs_cleaned, topics=new_topics)\n",
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrGhXedtrRCu"
      },
      "source": [
        "Congratulations! Now the topics are cleaned and ready to be explored through visualization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHkuC0etvqEI"
      },
      "source": [
        "**STEP VII:**\n",
        "\n",
        "TOPIC MAP NR. 1. This is a visual representation that shows how the identified topics relate to one another in terms of their content.\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "8KcV82tkAalw",
        "outputId": "ea7f975a-49e3-4137-aec1-ad61ea305ec8"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxDnWgaIrmY9"
      },
      "source": [
        "**STEP VIII:**\n",
        "\n",
        "TOPIC MAP NR. 2. The following map will allow us to visualize how the cleaned text documents are represented in a reduced-dimensional space.\n",
        "\n",
        "Run the three cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1a6c39771e4c4059ae2ca51c24b6c4a0",
            "5cc205d7c1c14085920fd61711690d30",
            "920d052110774f6e85244f081e694946",
            "1543b3343d5941fd9a41608df00e0d62",
            "6498cb4125d24d46980c36b08ed708b9",
            "118ae571201d42d398c51a9495352b47",
            "3feb3372a0e246d985ad3e60a3c405fe",
            "ec107d3ecf4047a99018a7d7226b08e4",
            "b17636468dec46e6b2c1ab502562ea25",
            "06ba2e299d18400c8befd83f1a3a765b",
            "347cd495f78b4e4e903926bd6bfd4188"
          ]
        },
        "collapsed": true,
        "id": "pvL7PDQUBptt",
        "outputId": "465bf360-9405-4205-f809-e4a8ee6f66d1"
      },
      "outputs": [],
      "source": [
        "embedding_model = sentence_model\n",
        "document_embeddings = embedding_model.encode(docs_cleaned, show_progress_bar=True)  #this converts text into numerical embeddings. \"show_progress_bar is highly optional, it just allows us to see the bar. I like progress bars.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "aU9XOe5YwO2G",
        "outputId": "a19ae47f-e699-42c2-bd11-20f77e9deaf8"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_documents(docs=docs_cleaned, embeddings=document_embeddings, hide_annotations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "TJ3mW6HNZPq9",
        "outputId": "d8fda8f5-9b1b-4c15-ab0e-243674fdf252"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYXhjIykrw9K"
      },
      "source": [
        "Well done! Now that you have a knowledge of the densest topics and of the most important clusters, it is time to **analyse them timewise**. We can do that by adding the topics created as a **third column** to our dataset. In this way, we will be able to see on every row comment, datetime and associated topic group.\n",
        "\n",
        "**STEP IX:**\n",
        "\n",
        "Run cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2cQFg9QznUL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "all_comments['topics'] = topics\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "csv_filename = r'' #fill in file name and path\n",
        "all_comments.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Print the absolute path so you can manually download it\n",
        "file_path = os.path.abspath(csv_filename)\n",
        "print(f\"File saved at: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congrats! DATA_ANALYSIS_4CHAN_I_ is completed use the .CSV file with the topics for the second analysis notebook 'DATA_ANALYSIS_4CHAN_II_'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06ba2e299d18400c8befd83f1a3a765b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118ae571201d42d398c51a9495352b47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1543b3343d5941fd9a41608df00e0d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ba2e299d18400c8befd83f1a3a765b",
            "placeholder": "​",
            "style": "IPY_MODEL_347cd495f78b4e4e903926bd6bfd4188",
            "value": " 2324/2324 [01:43&lt;00:00, 63.74it/s]"
          }
        },
        "1a6c39771e4c4059ae2ca51c24b6c4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cc205d7c1c14085920fd61711690d30",
              "IPY_MODEL_920d052110774f6e85244f081e694946",
              "IPY_MODEL_1543b3343d5941fd9a41608df00e0d62"
            ],
            "layout": "IPY_MODEL_6498cb4125d24d46980c36b08ed708b9"
          }
        },
        "347cd495f78b4e4e903926bd6bfd4188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3feb3372a0e246d985ad3e60a3c405fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc205d7c1c14085920fd61711690d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118ae571201d42d398c51a9495352b47",
            "placeholder": "​",
            "style": "IPY_MODEL_3feb3372a0e246d985ad3e60a3c405fe",
            "value": "Batches: 100%"
          }
        },
        "6498cb4125d24d46980c36b08ed708b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920d052110774f6e85244f081e694946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec107d3ecf4047a99018a7d7226b08e4",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b17636468dec46e6b2c1ab502562ea25",
            "value": 2324
          }
        },
        "b17636468dec46e6b2c1ab502562ea25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec107d3ecf4047a99018a7d7226b08e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
