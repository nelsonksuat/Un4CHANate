{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = r'C:\\Users\\Nelson Tausk\\Dataset_dataproject\\pol.csv'\n",
    "output_folder = r'C:\\Users\\Nelson Tausk\\Dataset_dataproject\\render_4d'\n",
    "\n",
    "chunk_size = 10000000 # Number of rows per chunk\n",
    "columns_to_extract = [4, 22]  # Indices of columns 4 and 23\n",
    "\n",
    "# Regex pattern to match strings containing \">>\"\n",
    "pattern = r\">>\"\n",
    "\n",
    "# Process the file in chunks\n",
    "chunks = pd.read_csv(\n",
    "    input_file,\n",
    "    engine='python',\n",
    "    chunksize=chunk_size,\n",
    "    on_bad_lines='skip',\n",
    "    delimiter=',',\n",
    "    quoting=3\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Extract columns 4 and 23 (indices 3 and 22) and drop missing values\n",
    "    selected_columns = chunk.iloc[:, columns_to_extract].copy()\n",
    "    selected_columns.columns = ['time', 'comment']  # Rename the columns for clarity\n",
    "    selected_columns = selected_columns.dropna()\n",
    "\n",
    "    # Filter out rows where 'comment' contains \">>\"\n",
    "    cleaned_data = selected_columns[~selected_columns['comment'].str.contains(pattern, na=False)]\n",
    "\n",
    "    # Define the output file path for this chunk\n",
    "    output_file = f\"{output_folder}/chunk_{i + 1}.csv\"\n",
    "\n",
    "    # Save the cleaned chunk to a CSV file\n",
    "    cleaned_data.to_csv(output_file, index=False, header=True)\n",
    "    print(f\"Cleaned chunk {i + 1} saved to {output_file}.\")\n",
    "\n",
    "print(\"All chunks processed and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
